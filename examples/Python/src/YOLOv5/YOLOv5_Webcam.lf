/**
 * @brief Example of a Deep Neural Network (YOLOv5) in LF.
 *
 * Please see README.md for instructions. This uses ultralytics/yolov5. Adapted from:
 * https://towardsdatascience.com/implementing-real-time-object-detection-system-using-pytorch-and-opencv-70bac41148f7
 */
target Python {
  keepalive: true,
  single-threaded: true  # OpenCV crashes if we use the multithreaded version.
}

import WebCamAsync from "VideoAsync.lf"
import Display from "Video.lf"

preamble {=
  BILLION = 1_000_000_000
  import cv2
=}

/**
 * A YOLOv5 DNN that takes a frame as input and produces object 'labels' and object label
 * coordinates (where each label/object is on the frame).
 */
reactor DNN {
  input frame               # Image input frame

  output labels             # Label outputs
  output label_coordinates  # Label coordinates
  output model              # Send the model to anyone who's interested

  state _model              # The DNN model
  state _device             # The device to use (e.g., cpu or cuda)
  preamble {=
    import torch
    from torch import hub
  =}

  reaction(startup) -> model {=
    # Load YOLOv5
    self._model = self.torch.hub.load("ultralytics/yolov5", "yolov5s", pretrained=True)
    # Find out if CUDA is supported
    self._device = "cuda" if self.torch.cuda.is_available() else 'cpu'
    # Send the model to device
    self._model.to(self._device)
    # Send the model to whoever is interested (other reactors)
    model.set(self._model)
  =}

  reaction(frame) -> labels, label_coordinates {=
    # Convert the frame into a tuple
    fr = [frame.value]
    # Run the model on the frame
    results = self._model(fr)
    # Extract the labels
    labels.set(results.xyxyn[0][:, -1].cpu().numpy())
    # Extract the coordinates for the label
    label_coordinates.set(results.xyxyn[0][:, :-1].cpu().numpy())
  =}
}

/** Plot frames with labels superimposed on top of each object in the frame. */
reactor Plotter(label_deadline = 100 msec) {
  input frame
  input labels
  input label_coordinates
  input model

  output result

  state _model  # Keep the model
  state _prev_time = 0

  /** Receive the DNN model */
  reaction(model) {=
    self._model = model.value
  =}

  /** Impose a deadline on object labels */
  reaction(labels) {=
    # DNN output was on time
  =} deadline(label_deadline) {=
    print(f"Received the DNN output late by about {(lf.time.physical() - lf.time.logical())/1000000}ms.")
  =}

  /**
   * Given a frame, object labels, and the corresponding object label coordinates, draw on the frame
   * and produce an output.
   */
  reaction(frame, labels, label_coordinates) -> result {=
    if  (not frame.is_present or
       not labels.is_present or
       not label_coordinates.is_present):
       sys.stderr.write("Error: Expected all inputs to be present at the same time.\n")
       request_stop()
       return

    # Get how many labels we have
    n = len(labels.value)
    x_shape, y_shape = frame.value.shape[1], frame.value.shape[0]
    for i in range(n):
      row = label_coordinates.value[i]
      # If score is less than 0.2 we avoid making a prediction.
      if row[4] < 0.2:
        continue
      x1 = int(row[0]*x_shape)
      y1 = int(row[1]*y_shape)
      x2 = int(row[2]*x_shape)
      y2 = int(row[3]*y_shape)
      bgr = (0, 255, 0) # color of the box
      classes = self._model.names # Get the name of label index
      label_font = cv2.FONT_HERSHEY_SIMPLEX #Font for the label.
      cv2.rectangle(frame.value, \
              (x1, y1), (x2, y2), \
               bgr, 2) #Plot the boxes
      cv2.putText(frame.value,\
            classes[int(labels.value[i])], \
            (x1, y1), \
            label_font, 0.9, bgr, 2) #Put a label over box.

    result.set(frame.value)
  =}

  reaction(shutdown) {=
    # Destroy the all windows now
    cv2.destroyAllWindows()
  =}
}

main reactor {
  # Offset allows time for the model to load.
  webcam = new WebCamAsync(offset = 2 s)
  dnn = new DNN()
  plotter = new Plotter()
  display = new Display()

  # Send the camera frame to the DNN to be process and to the plotter to be depicted
  (webcam.camera_frame)+ -> dnn.frame, plotter.frame
  # Send outputs of the DNN (object labels and their coordinates) to the plotter
  dnn.labels, dnn.label_coordinates -> plotter.labels, plotter.label_coordinates

  # Send the DNN model to the plotter. It will be used to extract the human-readable names
  # of each label.
  dnn.model -> plotter.model

  webcam.camera_frame ~> webcam.trigger

  plotter.result -> display.frame
}
