/**
 * This Lingua Franca (LF) program simulates an autonomous driving system inspired by Autoware's
 * general graph structure and constraints. The system involves two sensors, a Camera and a LIDAR,
 * generating periodic image and point-cloud data respectively. These data are processed by two
 * object detection reactors, which simulate GPU computation using simulated delays and threading.
 * The detected objects from both the image and LIDAR data are then merged in a DataFusion reactor.
 * This fusion reactor is designed to handle the arrival of data from both inputs before proceeding,
 * implementing a choke point that collapses multiple logical timelines into one.
 *
 * The fused data is passed to a Semantics reactor, which makes driving decisions based on the fused
 * data, and the resultant actuation command is passed to an Actuator reactor. The Actuator reactor
 * operates under a deadline, issuing a warning if this deadline is violated. Moreover, an
 * alternative SafetyBrake path exists that can trigger the actuation based on LIDAR input directly.
 * The whole system is designed to enforce a Logical Execution Time (LET) and meet end-to-end
 * deadlines while taking into account the worst-case execution times of different components. This
 * program offers a high-level simulation of real-time data processing and decision-making in
 * autonomous driving systems.
 */
// A lingua franca program with Autoware's general graph structure and constraints
// The tentative constraints are:
// - Sensors: Camera(phase=3, period=33) and LIDAR(phase=10, period=10)
// - LET=30ms or alternatively, the relative deadline is 30
// - Sensor Fusion causes merge (choke) points that collapse multiple logical timelines into one.
target C {
  keepalive: false
}

// Send a periodic image out
reactor Camera(offset: time = 0, period: time = 1 sec) {
  output image: string
  timer t(offset, period)

  reaction(t) -> image {=
    lf_set(image, "kitty");
  =}
}

// Send a periodic LIDAR pointcloud out
reactor LIDAR(offset: time = 0, period: time = 1 sec) {
  output pointcloud: string
  timer t(offset, period)

  reaction(t) -> pointcloud {=
    lf_set(pointcloud, "INTERSECTION");
  =}
}

// Simulate object detection on GPU
reactor ImageObjectDetection {
  input image: string
  output object: string

  state thread_id: pthread_t = 0

  preamble {=
    #include <pthread.h>

    void camera_callback(void* a) {
      // cudaDeviceSynchronize() and copy back goes here.
      lf_schedule(a, 0);
    }
    // Simulate time passing before a callback occurs instead of executing on GPU.
    void* camera_take_time(void* a) {
      struct timespec sleep_time = {(time_t) 0, (long)5000000}; // WCET for GPU is 5msec
      struct timespec remaining_time;
      nanosleep(&sleep_time, &remaining_time);
      camera_callback(a);
      return NULL;
    }
    pthread_t threadId;
  =}

  physical action CUDA(100 msec)

  reaction(image) -> CUDA {=
    // cudaMalloc(&y_state_d, SIZE);
    // cudaMemcpy(&y_state_d, y_state, SIZE, cudaMemcpyHosttoDevice);
    // kernel<<<1,1>>>(y_state_d);

    /* Busy wait for 2 msecs for now instead of calling CUDA kernels */
    interval_t sleep_time = MSEC(2);
    instant_t start_time = lf_time_physical();
    while (lf_time_physical() < start_time + sleep_time) {};

    pthread_create(&self->thread_id, NULL, &camera_take_time, CUDA);
  =}

  reaction(CUDA) -> object {=
    // cudaMalloc(&y_out_d, SIZE);

    // cudaMemcpy(&y_out, results_d, SIZE, cudaMemcpyDevicetoHost);

    // cudaDeviceSynchronize();



    lf_set(object, "DUMMY Results");
  =}
}

// Simulate LIDAR object detection on GPU
reactor LIDARObjectDetection {
  input pointcloud: string
  output object: string

  state thread_id: pthread_t = 0

  preamble {=
    #include <pthread.h>

    void LIDAR_callback(void* a) {
      // cudaDeviceSynchronize() and copy back goes here.
      lf_schedule(a, 0);
    }
    // Simulate time passing before a callback occurs instead of executing on GPU.
    void* LIDAR_take_time(void* a) {
      struct timespec sleep_time = {(time_t) 0, (long)12000000}; // WCET for LIDAR GPU is 12 msec
      struct timespec remaining_time;
      nanosleep(&sleep_time, &remaining_time);
      LIDAR_callback(a);
      return NULL;
    }
    pthread_t threadId;
  =}

  logical action CUDA(100 msec, 20 msec)

  reaction(pointcloud) -> CUDA {=
      // self->y_state = y_in;
      // cudaMalloc(&y_state_d, SIZE);
      // cudaMemcpy(&y_state_d, y_state, SIZE, cudaMemcpyHosttoDevice);
      // kernel<<<1,1>>>(y_state_d);
    //printf("LIDAR triggered at %llu\n", lf_time_physical());

      /* Busy wait for 2 msecs for now instead of calling CUDA kernels */
      interval_t sleep_time = MSEC(2);
      instant_t start_time = lf_time_physical();
      while (lf_time_physical() < start_time + sleep_time) {};

      pthread_create(&self->thread_id, NULL, &LIDAR_take_time, CUDA);
  =}

  reaction(CUDA) -> object {=
      // cudaMalloc(&y_out_d, SIZE);
    //printf("LIDAR triggered at %llu\n", lf_time_physical());
    // printf("LIDAR triggered at %llu\n", lf_time_logical());

      // cudaMemcpy(&y_out, results_d, SIZE, cudaMemcpyDevicetoHost);

      // cudaDeviceSynchronize();

      lf_set(object, "Hey look there is a kitty!");
  =}
}

// Fuse LIDAR and Camera detected objects
reactor DataFusion(threshold: time = 20 msec) {
  input imageobject: string
  input LIDARobject: string
  output object: string
  logical action both_ports_are_present(0)

  state tmpImageobject: string = ""
  state tmpImageobjectTag: time = 0
  state tmpLIDARobject: string = ""
  state tmpLIDARobjectTag: time = 0

  // Handle two ports
  reaction(imageobject, LIDARobject) -> both_ports_are_present {=
    if(imageobject->is_present)
    {
      self->tmpImageobject = imageobject->value;
      self->tmpImageobjectTag = lf_time_logical(); // Store the tag

      instant_t window = self->tmpLIDARobjectTag - lf_time_logical();

      if(LIDARobject->is_present)
      {
      lf_schedule(both_ports_are_present, 0);
      }

       else if(window < (long)1000000)
      {
        lf_schedule(both_ports_are_present, 0);
      }
      else
      {
        // instant_t elapsed = lf_time_physical() - lf_time_logical(); // How much time has passed - soft
        instant_t elapsed = self->threshold; // How much time has passed - hard
        instant_t remaining = (long)30000000 - elapsed; // How much time is left
        instant_t schedule_in = remaining - (long)8000000; // Combined WCET of the remaining reactions is 8 msec
        lf_schedule(both_ports_are_present, schedule_in);
      }
    // printf("Received image object at %llu physical and %llu logical.\n", lf_time_physical(), lf_time_logical());
    }
    else if(LIDARobject->is_present)
    {
      self->tmpLIDARobject = LIDARobject->value;
      self->tmpLIDARobjectTag = lf_time_logical(); // Store the tag

      instant_t window = self->tmpImageobjectTag - lf_time_logical();

      if( window < (long)1000000)
      {
        lf_schedule(both_ports_are_present, 0);
      }
      else
      {
      // instant_t elapsed = lf_time_physical() - lf_time_logical(); // How much time has passed - soft
        instant_t elapsed = self->threshold; // How much time has passed - hard
        instant_t remaining = (long)30000000 - elapsed; // How much time is left
        instant_t schedule_in = remaining - (long)8000000; // Combined WCET of the remaining reactions is 8 msec
        lf_schedule(both_ports_are_present, schedule_in);
      }
    // printf("Received LIDAR object at %llu physical and %llu logical.\n", lf_time_physical(), lf_time_logical());
    }
  =} deadline(threshold) {=
    printf("Deadline violation detected.\n");
  =}

  // Fuse
  reaction(both_ports_are_present) -> object {=
    printf("Fusion scheduled at: ( %llu , %llu ).\n", lf_time_physical(), lf_time_logical());
     //printf("Fusion: %llu\n", lf_time_physical());
    /* Busy wait for 2 msecs for now instead of calling CUDA kernels */
    interval_t sleep_time = MSEC(2);
    instant_t start_time = lf_time_physical();
    while (lf_time_physical() < start_time + sleep_time) {};
    lf_set(object, "fused");
  =}
}

// Make driving semantic decisions
reactor Semantics {
  input fusedObject: string
  output actuation: int

  reaction(fusedObject) -> actuation {=
      struct timespec sleep_time = {(time_t) 0, (long)6000000};
      struct timespec remaining_time;
      nanosleep(&sleep_time, &remaining_time);
    lf_set(actuation, 5);
  =}
}

reactor Actuator(threshold: time = 33 msec) {
  input actuation: int

  reaction(actuation) {=
    // Do nothing;
    printf("Actuator scheduled at: ( %llu , %llu ).\n", lf_time_physical(), lf_time_logical());
     // printf("Actuator: %llu\n", lf_time_physical());
  =} deadline(threshold) {=
    printf("Deadline violation detected in Actuator.\n");
  =}
}

/** An alternative path exists between the LIDAR and the actuator for the safety brake system */
reactor SafetyBrake {
  input LIDARPointCloud: string
  output actuation: int

  reaction(LIDARPointCloud) -> actuation {=
    lf_set(actuation, 5);
  =}
}

// End-to-end daedline should be 33ms
// LET must be enforced with an output period of 33ms
// GPU is used
// Sub-deadlines (i.e., reaction deadlines) must not be violated
main reactor Autoware {
  // Camera has a phase (startup time) of 3 msec and a period of 33 msec
  c = new Camera(offset = 3 msec, period = 33 msec)
  // Lidar has a phase (spooling up time) of 10 msec and a period of 10 msec
  l = new LIDAR(offset = 10 msec, period = 10 msec)

  iobjectdetection = new ImageObjectDetection()
  c.image -> iobjectdetection.image

  lobjectdetection = new LIDARObjectDetection()
  l.pointcloud -> lobjectdetection.pointcloud

  // Choke point
  fuse = new DataFusion()
  iobjectdetection.object -> fuse.imageobject
  lobjectdetection.object -> fuse.LIDARobject

  sem = new Semantics()
  fuse.object -> sem.fusedObject

  ac = new Actuator()
  sem.actuation -> ac.actuation

  // An alternative path that activates the safety brake system based on LIDAR input
  sb = new SafetyBrake()
  // sb.actuation -> ac.actuation; // Cannot construct the alternative path because actuation may only be connected to a single upstream port
  l.pointcloud -> sb.LIDARPointCloud
}
